{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.datasets import *\n",
    "from pathlib import Path\n",
    "import html\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available\n",
      "PyTorch version:  1.0.0.dev20190320\n"
     ]
    }
   ],
   "source": [
    "# Check that the latest 1.0.0 build of PyTorch has been installed \n",
    "# alongside fastai\n",
    "import torch\n",
    "print(\"Cuda available\" if torch.cuda.is_available() is True else \"CPU\")\n",
    "print(\"PyTorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('/home/dell/Code/fastai_examples/pubmed-rct-200k/')\n",
    "PATH.mkdir(exist_ok=True)\n",
    "DATA_PATH=Path('/home/dell/Code/fastai_examples/data/pubmed-rct-200k')\n",
    "DATA_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = untar_data(\"http://files.fast.ai/data/examples/imdb_sample.tgz\",dest=DATA_PATH)\n",
    "#path = Path('/home/dell/Code/fastai_examples/data/imdb_sample/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcess = False\n",
    "modelTrain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataProcess:\n",
    "    testData = pd.read_csv(DATA_PATH/'test.txt', sep=\"\\t\", header=None, comment='#')\n",
    "    testData.columns = [\"label\", \"text\"]\n",
    "    testData.dropna(inplace=True)\n",
    "    testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataProcess:\n",
    "    trainData = pd.read_csv(DATA_PATH/'train.txt', sep=\"\\t\", header=None, comment='#')\n",
    "    trainData.columns = [\"label\", \"text\"]\n",
    "    trainData.dropna(inplace=True)\n",
    "    trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.7/site-packages/torch/serialization.py:452: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "if dataProcess:\n",
    "  # Language model data\n",
    "  data_lm = TextLMDataBunch.from_df(PATH,train_df=trainData, valid_df = testData)\n",
    "  data_lm.save(PATH/'data_lm_export.pkl')\n",
    "  # Classifier model data\n",
    "  data_clas = TextClasDataBunch.from_df(PATH, train_df=trainData,valid_df = testData , \\\n",
    "                                        vocab=data_lm.train_ds.vocab, bs=32)\n",
    "  data_clas.save(PATH/'data_clas_export.pkl')\n",
    "else:\n",
    "  data_lm = load_data(PATH, file='data_lm_export.pkl')\n",
    "  data_clas = load_data(PATH, file='data_clas_export.pkl', bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if modelTrain:\n",
    "    learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5, pretrained=False)\n",
    "    learn.lr_find()\n",
    "    learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if modelTrain:\n",
    "    preTrainedWt103Path = Path('/home/dell/Code/fastai_examples/data/models/wt103')\n",
    "    learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5, pretrained=False)\n",
    "    learn.load_pretrained(wgts_fname = preTrainedWt103Path/'fwd_wt103.h5', itos_fname = preTrainedWt103Path/'itos_wt103.pkl', strict=False )\n",
    "    learn.fit_one_cycle(20, 1e-2)\n",
    "    pathModel = learn.save(PATH/\"trained_model\")\n",
    "else:\n",
    "    learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5, pretrained=False)\n",
    "    learn.load(PATH/\"trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.52.dev0\n"
     ]
    }
   ],
   "source": [
    "print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "#learn.predict(\"TP53 is an important gene \", n_words=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"i like apples\",\n",
    "         \"i want to buy some apples\",\n",
    "         \"where is your cell phone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp2 = [\"i like apples and orange\",\n",
    "          \"i am going to buy some apples and orange\",\n",
    "          \"you like apples and orange\",\n",
    "         \"you hate all fruits especially apples and orange\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp3 = [\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp4 = [\"acupuncture has no systemic hazard for pregnancy\",\n",
    "         \"anxiety might have harmful effects for pregnancy\",\n",
    "         \"anxiety is bad for pregnancy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp5 = [\"protein\",\n",
    "         \"gene\",\n",
    "         \"cell\",\n",
    "         \"asthma\",\n",
    "         \"lung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_test_input = x_inp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "n_cpu = multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().process_all(partition_by_cores(similarity_test_input,n_cpu-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['let', \"'s\", 'talk', 'about', 'fruits', 'for', 'a', 'second', '.', 'xxmaj', 'apples', 'are', 'nice', '.', 'xxmaj', 'oranges', 'too', '.', 'i', 'kinda', 'like', 'them', '.']\n",
      "['i', 'compared', 'the', 'prices', 'of', 'apples', 'and', 'oranges', 'at', 'walmart', 'and', 'kroger', 'stores']\n",
      "['oh', 'you', 'wanna', 'talk', 'about', 'apples', '.', 'sure', '.', 'i', 'am', 'not', 'sure', 'if', 'i', 'have', 'said', 'this', 'before', 'but', 'i', 'do', 'like', 'them', 'and', 'oranges', '.']\n"
     ]
    }
   ],
   "source": [
    "for t in tok:\n",
    "    print(t[2:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[246, 11221, 459, 6401, 24, 19, 415, 9, 4, 25410, 92, 16975, 9, 4, 4527, 9, 300, 1624, 1204]\n",
      "[300, 56, 10, 13808, 11, 25410, 12, 30, 12, 7925]\n",
      "[2764, 11760, 11221, 459, 25410, 9, 21590, 9, 300, 2955, 45, 21590, 378, 300, 132, 10107, 40, 145, 89, 300, 1113, 1624, 1204, 12, 9]\n"
     ]
    }
   ],
   "source": [
    "X = [[data_lm.vocab.stoi[o1] for o1 in o if data_lm.vocab.stoi[o1] != 0] for o in tok];\n",
    "for truncX in X:\n",
    "    print(truncX[2:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AWD_LSTM(\n",
       "  (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "  (encoder_dp): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): WeightDropout(\n",
       "      (module): LSTM(400, 1150, batch_first=True)\n",
       "    )\n",
       "    (1): WeightDropout(\n",
       "      (module): LSTM(1150, 1150, batch_first=True)\n",
       "    )\n",
       "    (2): WeightDropout(\n",
       "      (module): LSTM(1150, 400, batch_first=True)\n",
       "    )\n",
       "  )\n",
       "  (input_dp): RNNDropout()\n",
       "  (hidden_dps): ModuleList(\n",
       "    (0): RNNDropout()\n",
       "    (1): RNNDropout()\n",
       "    (2): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for sentence in X:\n",
    "        #resizeLength = len(x_inp4)\n",
    "        resizeLength = len(sentence[2:-2])\n",
    "        input_sentence = tensor(sentence[2:-2])\n",
    "        input_sentence.resize_(resizeLength,1)\n",
    "        # sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "        tmpEmbded = m[0](input_sentence.cuda())\n",
    "        embeddings.append(tmpEmbded[0][2].mean(0)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kk0=m[0](input0.cuda())\n",
    "#kk1=m[0](input1.cuda())\n",
    "#kk2=m[0](input2.cuda())\n",
    "#kk3=m[0](input3.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "#kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "#kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "#kk3 = (kk3[0][2][0][-1]) # 4rd sentence encoding 400 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity - to check quality of our sentence encoder\n",
    "def cos_sim(v1,v2):\n",
    "    return F.cosine_similarity(tensor(v1).unsqueeze(0),tensor(v2).unsqueeze(0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " 'oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\n",
      "... with ....\n",
      "let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\n",
      "1.0\n",
      "let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\n",
      "... with ....\n",
      "i compared the prices of apples and oranges at walmart and kroger stores\n",
      "0.42818450927734375\n",
      "let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\n",
      "... with ....\n",
      "oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\n",
      "0.6155552268028259\n",
      "\n",
      "\n",
      "i compared the prices of apples and oranges at walmart and kroger stores\n",
      "... with ....\n",
      "let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\n",
      "0.42818450927734375\n",
      "i compared the prices of apples and oranges at walmart and kroger stores\n",
      "... with ....\n",
      "i compared the prices of apples and oranges at walmart and kroger stores\n",
      "1.0\n",
      "i compared the prices of apples and oranges at walmart and kroger stores\n",
      "... with ....\n",
      "oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\n",
      "0.5646359324455261\n",
      "\n",
      "\n",
      "oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\n",
      "... with ....\n",
      "let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\n",
      "0.6155552268028259\n",
      "oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\n",
      "... with ....\n",
      "i compared the prices of apples and oranges at walmart and kroger stores\n",
      "0.5646359324455261\n",
      "oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\n",
      "... with ....\n",
      "oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\n",
      "0.9999999403953552\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        print(similarity_test_input[i] + \"\\n... with ....\\n\" + similarity_test_input[j])\n",
    "        print(cos_sim(embeddings[i],embeddings[j]).item())\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
