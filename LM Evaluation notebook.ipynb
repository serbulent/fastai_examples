{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/aclImdb/')\n",
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "LM_PATH=Path('data/imdb_lm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 90000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing LM model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=250\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace weights from classifier-encoder (not LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm1')\n",
    "#learner.load_encoder('lm1_enc')\n",
    "learner.load_encoder('clas_2_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal: Encode 3 sentences using a pre-trained encoder and check the similarity scores between each pair of sentences. We use 2 methods to calculate semantic similarity: cosine similarity and inner product of encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity - to check quality of our sentence encoder\n",
    "def cos_sim(v1,v2):\n",
    "    return F.cosine_similarity(T(v1).unsqueeze(0),T(v2).unsqueeze(0)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1 - simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"i like apples\",\n",
    "         \"i want to buy some apples\",\n",
    "         \"where is your cell phone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'like', 'apples'],\n",
       " ['i', 'want', 'to', 'buy', 'some', 'apples'],\n",
       " ['where', 'is', 'your', 'cell', 'phone']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 52, 13154], [12, 203, 8, 808, 64, 13154], [134, 9, 146, 2739, 1668]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - sentence level encoding....10 words 400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - sentence level encoding....10 words 400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - sentence level encoding....10 words 400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples', 'i want to buy some apples', 'where is your cell phone']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.840636134147644, 0.23084455728530884, 0.14089250564575195)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7731147"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7360966"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000539"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2 - increase sentence complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"i like apples and oranges\",\n",
    "         \"i hate all fruits especially apples and oranges\",\n",
    "         \"i am going to buy some apples and oranges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'like', 'apples', 'and', 'oranges'],\n",
       " ['i', 'hate', 'all', 'fruits', 'especially', 'apples', 'and', 'oranges'],\n",
       " ['i', 'am', 'going', 'to', 'buy', 'some', 'apples', 'and', 'oranges']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 52, 13154, 5, 20864],\n",
       " [12, 738, 43, 22144, 280, 13154, 5, 20864],\n",
       " [12, 261, 182, 8, 808, 64, 13154, 5, 20864]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - sentence level encoding....400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - sentence level encoding....400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - sentence level encoding....400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples and oranges',\n",
       " 'i hate all fruits especially apples and oranges',\n",
       " 'i am going to buy some apples and oranges']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5945706367492676, 0.9124612808227539, 0.5243738293647766)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96930826"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2086678"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501094"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 3 - more complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['let',\n",
       "  \"'s\",\n",
       "  'talk',\n",
       "  'about',\n",
       "  'fruits',\n",
       "  'for',\n",
       "  'a',\n",
       "  'second',\n",
       "  '.',\n",
       "  'apples',\n",
       "  'are',\n",
       "  'nice',\n",
       "  '.',\n",
       "  'oranges',\n",
       "  'too',\n",
       "  '.',\n",
       "  'i',\n",
       "  'kinda',\n",
       "  'like',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'compared',\n",
       "  'the',\n",
       "  'prices',\n",
       "  'of',\n",
       "  'apples',\n",
       "  'and',\n",
       "  'oranges',\n",
       "  'at',\n",
       "  'walmart',\n",
       "  'and',\n",
       "  'kroger',\n",
       "  'stores'],\n",
       " ['oh',\n",
       "  'you',\n",
       "  'wanna',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'apples',\n",
       "  '.',\n",
       "  'sure',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'sure',\n",
       "  'if',\n",
       "  'i',\n",
       "  'have',\n",
       "  'said',\n",
       "  'this',\n",
       "  'before',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  'like',\n",
       "  'them',\n",
       "  'and',\n",
       "  'oranges',\n",
       "  '.']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[302,\n",
       "  16,\n",
       "  713,\n",
       "  58,\n",
       "  22144,\n",
       "  22,\n",
       "  6,\n",
       "  349,\n",
       "  3,\n",
       "  13154,\n",
       "  33,\n",
       "  358,\n",
       "  3,\n",
       "  20864,\n",
       "  116,\n",
       "  3,\n",
       "  12,\n",
       "  2040,\n",
       "  52,\n",
       "  110,\n",
       "  3],\n",
       " [12, 1128, 2, 12023, 7, 13154, 5, 20864, 44, 17680, 5, 0, 5400],\n",
       " [452,\n",
       "  26,\n",
       "  2890,\n",
       "  713,\n",
       "  58,\n",
       "  13154,\n",
       "  3,\n",
       "  273,\n",
       "  3,\n",
       "  12,\n",
       "  261,\n",
       "  32,\n",
       "  273,\n",
       "  62,\n",
       "  12,\n",
       "  36,\n",
       "  326,\n",
       "  13,\n",
       "  176,\n",
       "  24,\n",
       "  12,\n",
       "  57,\n",
       "  52,\n",
       "  110,\n",
       "  5,\n",
       "  20864,\n",
       "  3]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - sentence level encoding....400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - sentence level encoding....400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - sentence level encoding....400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " 'oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19936618208885193, 0.21164974570274353, 0.9665364027023315)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37327933"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3976462"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.457068"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 4 - really complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"there is no comparison here. you are comparing apples to oranges\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"i don't see anything common between these two categories.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'comparison',\n",
       "  'here',\n",
       "  '.',\n",
       "  'you',\n",
       "  'are',\n",
       "  'comparing',\n",
       "  'apples',\n",
       "  'to',\n",
       "  'oranges'],\n",
       " ['i',\n",
       "  'compared',\n",
       "  'the',\n",
       "  'prices',\n",
       "  'of',\n",
       "  'apples',\n",
       "  'and',\n",
       "  'oranges',\n",
       "  'at',\n",
       "  'walmart',\n",
       "  'and',\n",
       "  'kroger',\n",
       "  'stores'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'see',\n",
       "  'anything',\n",
       "  'common',\n",
       "  'between',\n",
       "  'these',\n",
       "  'two',\n",
       "  'categories',\n",
       "  '.']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[53, 9, 73, 1884, 148, 3, 26, 33, 4324, 13154, 8, 20864],\n",
       " [12, 1128, 2, 12023, 7, 13154, 5, 20864, 44, 17680, 5, 0, 5400],\n",
       " [12, 57, 29, 83, 255, 1116, 222, 150, 126, 9281, 3]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - sentence level encoding....400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - sentence level encoding....400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - sentence level encoding....400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there is no comparison here. you are comparing apples to oranges',\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " \"i don't see anything common between these two categories.\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5689688324928284, 0.1944683939218521, 0.12143591046333313)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2207007"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3840915"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21974534"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: 404290\n"
     ]
    }
   ],
   "source": [
    "QUESTION_PAIRS_FILE = './datasets/quora_duplicate_questions.tsv'\n",
    "#print(\"Processing\", QUESTION_PAIRS_FILE)\n",
    "\n",
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "with open(QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        question1.append(row['question1'])\n",
    "        question2.append(row['question2'])\n",
    "        is_duplicate.append(int(row['is_duplicate']))\n",
    "\n",
    "print('Question pairs: %d' % len(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market in india?',\n",
       " 'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       " 'How can I increase the speed of my internet connection while using a VPN?',\n",
       " 'Why am I mentally very lonely? How can I solve it?',\n",
       " 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n",
       " 'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n",
       " 'Should I buy tiago?',\n",
       " 'How can I be a good geologist?',\n",
       " 'When do you use シ instead of し?',\n",
       " 'Motorola (company): Can I hack my Charter Motorolla DCX3400?']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market?',\n",
       " 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?',\n",
       " 'How can Internet speed be increased by hacking through DNS?',\n",
       " 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?',\n",
       " 'Which fish would survive in salt water?',\n",
       " \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\",\n",
       " 'What keeps childern active and far from phone and video games?',\n",
       " 'What should I do to be a great geologist?',\n",
       " 'When do you use \"&\" instead of \"and\"?',\n",
       " 'How do I hack Motorola DCX3400 for free internet?']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_duplicate[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_q1 = Tokenizer.proc_all_mp(partition_by_cores(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_q2 = Tokenizer.proc_all_mp(partition_by_cores(question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'step',\n",
       "  'by',\n",
       "  'step',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'in',\n",
       "  'share',\n",
       "  'market',\n",
       "  '?'],\n",
       " ['what',\n",
       "  'would',\n",
       "  'happen',\n",
       "  'if',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'government',\n",
       "  'stole',\n",
       "  'the',\n",
       "  'kohinoor',\n",
       "  '(',\n",
       "  'koh',\n",
       "  '-',\n",
       "  'i',\n",
       "  '-',\n",
       "  'noor',\n",
       "  ')',\n",
       "  'diamond',\n",
       "  'back',\n",
       "  '?'],\n",
       " ['how',\n",
       "  'can',\n",
       "  'internet',\n",
       "  'speed',\n",
       "  'be',\n",
       "  'increased',\n",
       "  'by',\n",
       "  'hacking',\n",
       "  'through',\n",
       "  't_up',\n",
       "  'dns',\n",
       "  '?'],\n",
       " ['find',\n",
       "  'the',\n",
       "  'remainder',\n",
       "  'when',\n",
       "  '[',\n",
       "  'math]23^{24',\n",
       "  '}',\n",
       "  '[',\n",
       "  '/',\n",
       "  'math',\n",
       "  ']',\n",
       "  'is',\n",
       "  'divided',\n",
       "  'by',\n",
       "  '24,23',\n",
       "  '?'],\n",
       " ['which', 'fish', 'would', 'survive', 'in', 'salt', 'water', '?'],\n",
       " ['i',\n",
       "  \"'m\",\n",
       "  'a',\n",
       "  'triple',\n",
       "  'capricorn',\n",
       "  '(',\n",
       "  'sun',\n",
       "  ',',\n",
       "  'moon',\n",
       "  'and',\n",
       "  'ascendant',\n",
       "  'in',\n",
       "  'capricorn',\n",
       "  ')',\n",
       "  'what',\n",
       "  'does',\n",
       "  'this',\n",
       "  'say',\n",
       "  'about',\n",
       "  'me',\n",
       "  '?'],\n",
       " ['what',\n",
       "  'keeps',\n",
       "  'childern',\n",
       "  'active',\n",
       "  'and',\n",
       "  'far',\n",
       "  'from',\n",
       "  'phone',\n",
       "  'and',\n",
       "  'video',\n",
       "  'games',\n",
       "  '?'],\n",
       " ['what', 'should', 'i', 'do', 'to', 'be', 'a', 'great', 'geologist', '?'],\n",
       " ['when',\n",
       "  'do',\n",
       "  'you',\n",
       "  'use',\n",
       "  '\"',\n",
       "  '&',\n",
       "  '\"',\n",
       "  'instead',\n",
       "  'of',\n",
       "  '\"',\n",
       "  'and',\n",
       "  '\"',\n",
       "  '?'],\n",
       " ['how',\n",
       "  'do',\n",
       "  'i',\n",
       "  'hack',\n",
       "  'motorola',\n",
       "  't_up',\n",
       "  'dcx3400',\n",
       "  'for',\n",
       "  'free',\n",
       "  'internet',\n",
       "  '?']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_q2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = tok_q1 + tok_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(p for o in ques for p in o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 852054),\n",
       " ('the', 377634),\n",
       " ('what', 324433),\n",
       " ('is', 271122),\n",
       " ('i', 223363),\n",
       " ('how', 220656),\n",
       " ('a', 211277),\n",
       " ('to', 205717),\n",
       " ('in', 196940),\n",
       " ('do', 169773),\n",
       " ('of', 159862),\n",
       " ('are', 146580),\n",
       " ('and', 133925),\n",
       " ('can', 114550),\n",
       " ('for', 104498),\n",
       " (',', 98321),\n",
       " ('t_up', 97217),\n",
       " ('you', 93102),\n",
       " ('why', 84030),\n",
       " ('it', 71057),\n",
       " ('my', 70930),\n",
       " ('best', 70596),\n",
       " ('on', 60715),\n",
       " ('does', 59502),\n",
       " ('.', 49499)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', '?', 'the', 'what', 'is', 'i', 'how', 'a', 'to']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41665"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', '?', 'the', 'what', 'is', 'i', 'how', 'a', 'to']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "list(stoi)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.array([[stoi[o] for o in p] for p in tok_q1])\n",
    "q2 = np.array([[stoi[o] for o in p] for p in tok_q2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290,), (404290,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.shape,q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[4, 5, 3, 1254, 69, 1254, 2576, 9, 589, 10, 773, 390, 10, 43, 2]'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(q1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in',\n",
       "       'india', '?'], dtype='<U65')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos_arr = np.array(itos)\n",
    "itos_arr[q1[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('q1.npy', q1)\n",
    "np.save('q2.npy', q2)\n",
    "pickle.dump(itos, open('itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41665, 404290)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos) #vocab size\n",
    "vs,len(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.encoder.weight', '0.encoder_with_dropout.embed.weight', '0.rnns.0.module.weight_ih_l0', '0.rnns.0.module.bias_ih_l0', '0.rnns.0.module.bias_hh_l0', '0.rnns.0.module.weight_hh_l0_raw', '0.rnns.1.module.weight_ih_l0', '0.rnns.1.module.bias_ih_l0', '0.rnns.1.module.bias_hh_l0', '0.rnns.1.module.weight_hh_l0_raw', '0.rnns.2.module.weight_ih_l0', '0.rnns.2.module.bias_ih_l0', '0.rnns.2.module.bias_hh_l0', '0.rnns.2.module.weight_hh_l0_raw', '1.decoder.weight'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400,),\n",
       " array([-0.0183 , -0.13826,  0.01438, -0.01285,  0.00407,  0.01944,  0.01149, -0.13282, -0.02295, -0.01722],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0) \n",
    "row_m.shape, row_m[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix and take token weights from wikitext103 if available\n",
    "# Use 60002 instead of 41665 for future embedding matrix where backbone encoder needs to be loaded.\n",
    "# not needed for simple model\n",
    "new_w = np.zeros((60002, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 400)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60002, 400])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts['1.decoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_keep = np.random.rand(len(q1))>0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_trn = q1[trn_keep]\n",
    "q2_trn = q2[trn_keep]\n",
    "lbl_trn = np.asarray(is_duplicate)[trn_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([lbl_trn]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(T(np.array([lbl_trn[101]]).T)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363309,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_val = q1[~trn_keep]\n",
    "q2_val = q2[~trn_keep]\n",
    "lbl_val = np.asarray(is_duplicate)[~trn_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40981, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_val = np.asarray([lbl_val]).T\n",
    "lbl_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363309, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_trn = np.asarray([lbl_trn]).T\n",
    "lbl_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40981)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_val = lbl_val.T\n",
    "lbl_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 363309)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_trn = lbl_trn.T\n",
    "lbl_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41665, 400)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs,em_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, X, y): self.x1,self.x2,self.y = X[0],X[1],y\n",
    "    def __getitem__(self, idx): return A(self.x1[idx], self.x2[idx], (T(self.y[idx]).float()))\n",
    "    def __len__(self): return len(self.x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = PairDataset(X=[q1_trn,q2_trn],y=(lbl_trn).T)\n",
    "val_ds = PairDataset(X=[q1_val,q2_val],y=(lbl_val).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   20,    13,    74,    92,    66,   849,  3124,   129,    33,    13, 10557,  1314,    24,   149,\n",
       "            2]),\n",
       " array([  20,   11,   45,  216,   66,  129,   28,   15,   29, 1314,  505,   69,  149,    2]),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds.__getitem__(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to run with larger bs because of DataLoader transpose issue\n",
    "bs=100\n",
    "#bs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False) #, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False) #, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 34, 1), (37, 38, 1), (51, 37, 1), (36, 46, 1), (37, 37, 1)]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x1),len(x2),len(y)) for x1,x2,y in its]\n",
    "#[((y)) for x1,x2,y in its]\n",
    "#next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[i])\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,nl = 128,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairRNN(nn.Module):\n",
    "    #def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "    def __init__(self, vecs, itos, em_sz, nh, out_sl=75, nl=2, bs=100):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl,self.bs = nl,nh,out_sl,bs\n",
    "        self.emb = create_emb(vecs, itos, em_sz)\n",
    "        self.emb_drop = nn.Dropout(0.15)\n",
    "        self.gru = nn.GRU(em_sz, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out = nn.Linear(nh, em_sz, bias=False)\n",
    "        \n",
    "    def forward(self, inp1, inp2):\n",
    "        bs = self.bs\n",
    "        h = self.initHidden(bs)\n",
    "        emb1 = self.emb_drop(self.emb(inp1))\n",
    "        emb2 = self.emb_drop(self.emb(inp2))\n",
    "        out_1, h1 = self.gru(emb1, h)\n",
    "        out_2, h2 = self.gru(emb2, h)\n",
    "        h1 = self.out(h1)\n",
    "        h2 = self.out(h2)\n",
    "        return 1 - F.cosine_similarity(h1[1],h2[1],dim=1)#[0].mean(dim=1)\n",
    "        #return h1[1]\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "rnn = PairRNN(new_w, itos, em_sz, nh, bs=bs)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = nn.L1Loss()\n",
    "learn.metrics = [accuracy]\n",
    "#nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()\n",
    "#learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08251e5ea182421db6f2279c3dcf1a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/3634 [00:06<44:42,  1.35it/s, loss=0.391]    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/a8an18/conda/anaconda3/envs/fastai-cpu/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/a8an18/conda/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/a8an18/conda/anaconda3/envs/fastai-cpu/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1529/3634 [26:19<36:14,  1.03s/it, loss=0.376]"
     ]
    }
   ],
   "source": [
    "learn.fit(0.01, 1, cycle_len=12, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model - with backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
